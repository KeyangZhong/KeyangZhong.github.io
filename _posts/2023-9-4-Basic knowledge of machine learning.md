
## 距离计算
### 欧式距离（Euclidean distance）
$$
d(x,y) = \sqrt{\sum_{i=1}^n (x_i-y_i)^2}
$$
### 曼哈顿距离（Manhattan distance
）
$$
d(x,y) = \sum_{i=1}^n |x_i-y_i|
$$
### 切比雪夫距离（Chebyshev distance）
$$
d(x,y) = \max_{i=1}^n |x_i-y_i|
$$
### 闵氏距离（Minkowski Distance）
$$
d(x,y) = \left(\sum_{i=1}^n |x_i-y_i|^p\right)^{\frac{1}{p}}
$$
其中$p$是一个变参数，闵氏距离定义的是一组距离公式。当$p=1$时，是曼哈顿距离；$p=2$时，是欧式距离;$p\rightarrow∞$时，是契比雪夫距离。
闵氏距离的缺点主要有两个：
1. 将各个分量的量纲(scale)，也就是“单位”当作相同的看待了。
没有考虑各个分量的分布(期望，方差)可能是不同的。
### 标准化欧式距离（Normalized Euclidean distance）
$$
d(x,y) = \sqrt{\sum_{i=1}^n \left(\frac{x_i-y_i}{s_i}\right)^2}\\
s = \sqrt{\frac{1}{N}\sum_{i=1}^N (x_i-\bar{x})^2}
$$
**贝塞尔修正：**
在上面的标准差公式中，存在一个值为$N$的分母，其作用为将计算得到的累计偏差进行平均，从而消除数据集大小对计算数据离散程度所产生的影响。不过，使用$N$所计算得到的方差即标准差只能用来表示该数据集本身的离散程度；如果数据集是某个更大的研究对象的样本，即数据时抽样出来的，那么在计算改研究对象的离散程度时，就需要对上述方差公式和标准差公式进行贝尔塞修正，即将$N$替换为$N-1$。
是否使用贝尔塞修正，需要根据数据集的性质来决定。如果只是想要计算数据集本身的离散程度，那么就使用未修正的公式；如果数据集是一个样本，而想要计算的是样本所表达对象的离散程度，就使用贝尔塞修正后的公式。在特殊情况下，如果该数据集相较总体而言是一个极大的样本，在这种情况下，该样本数据集不可能错过任何异常值（outlier），此时可以使用未修正的公式来计算数据集总体的离散程度。
### 余弦相似度（Cosine similarity）
$$
\cos(\theta) = \frac{x \cdot y}{\|x\|\|y\|} = \frac{\sum_{i=1}^n x_i y_i}{\sqrt{\sum_{i=1}^n x_i^2} \sqrt{\sum_{i=1}^n y_i^2}}
$$
### 相关系数（Correlation coefficient）
用来衡量两变量间相关关系的大小
### KL散度（Kullback-Leibler divergence）
KL散度是两个概率分布$P$和$Q$差别的非对称性度量。
## 基本概念
### 输入空间，特征空间，输出空间
在监督学习中，将输入和输出所有可能的取值的集合分别称为**输入空间(input space)**和**输出空间(output space)**。
每个具体的输入是一个实例(instance)， 通常由特征向量(feature vector)表示。这时，所有特征向量存在的空间称为**特征空间(feature space)**。
在监督学习的过程中, 将输入和输出看作是定义在输入空间和输出空间上的随机变量的取值，习惯上**输入变量**和**输出变量**分别用大写字母 $X , Y$ 表示。输入变量的取值用小写字母 $x$ 表示，输出变量的取值用小写字母 $y$ 表示。
### 联合概率分布
监督学习中假设输入与输出变量$X,Y$遵循联合概率分布$P(X,Y)$。$P(X,Y)$表示分布函数或概率密度函数。**$X,Y$遵循联合概率分布的假设是监督学习关于数据的基本假设。**
### 假设空间
输入空间$X$和输出空间$Y$构成一个样本空间。对于样本空间$(x,y)\in(X,Y)$，假定存在一个位置的真实映射（决策函数）$f:X\rightarrow Y$使得
$$
y=f(X)\\
或者真实条件概率分布\\
p(y|x)
$$
监督学习中的模型可以是概率模型或者是非概率模型，分别有由条件概率分布$p(y|x)$和决策函数$y=f(x)$表示。机器学习的目标是找到一个模型来近似真实映射函数或真实条件概率分布。**根据经验来确定一个假设函数集合$F$，这个集合成为假设空间（hypothesis space）。**假设空间的确定意味着学习范围的确定。
假设空间通常为一个参数化的函数族：
$$
F=f(x,\theta)|\theta \in \mathbb{R}^m
$$
其中$f(x,\theta)|\theta$表示假设空间中的模型，$\theta$表示一组可以学习的参数，$m$为参数的数量。
## 机器学习三要素
三个基本要素：**模型，学习准则，优化算法。**
通过一个学习算法$A$，在训练集$T$上找到一组参数$θ^*$，使得函数$f(x,\theta^*)$可以近似真实的映射关系。这个过程为学习或训练过程，函数$f(x,\theta^*)$称为模型。
- **模型：** 模型就是要学习的条件概率分布或决策函数。模型的假设空间$F$ 包含所有的条件概率分布或决策函数。**学习的目标就是，通过观察假设空间在训练集上的特性，从中选择一个理想的假设(hypothesis)** $f∗∈F$ 。
- **学习准则：** 统计学习的目标在于从假设空间中学习最优模型。**有了模型的假设空间后，统计学习需要确定使用什么样的准则进行学习或者选择最优模型。**这其中就涉及到**期望风险最小化**、**经验风险最小化**和**结构风险最小化**等学习准则。
- **优化算法：** 在确定了训练集$T$ 、假设空间$F$ 以及学习准则后，如何找到最优的模型$f(x,\theta^*)$就成了一个最优化问题。机器学习的训练过程其实就是最优化问题的求解过程。
## 机器学习准则
**损失函数：** 度量模型一次预测好坏。

**风险函数：** 度量平均意义下的模型预测好坏。
### 经验风险最小化
经验风险是对训练集中的所有样本点损失函数的平均最小化。经验风险越小说明模型对训练集的你和程度越好。
### 期望风险最小化
期望风险表示的是全局的概念，表示决策函数对所有样本$<X,Y>$拟合能力的大小，经验风险是局部的概念。理想的决策模型是对所有的样本损失函数最小（即期望风险最小），但是期望风险函数往往是不可得到的，即上式中，$X与Y$ 的联合分布函数不容易得到。
### 经验风险与期望风险之间的联系与区别
- 经验风险是局部的，基于训练集所有样本点损失函数最小化的。
- 期望风险是全局的，是基于所有样本点的损失函数最小化的。
- 经验风险函数是现实的，可求的；期望风险函数是理想化的，不可求的。
### 结构化风险
结构风险最小化是未来防止过拟合提出的策略，结构化风险最小化等价于正则化。结构风险在经验风险上加上表示模型复杂度的正则化项或惩罚项。
## 机器学习范式
||监督学习（supervised）|半监督学习（semi-supervised）|无监督学习（unsupervised）|强化学习（reinforcement learning）|
|---------|---------|---------|---------|---------|
||训练集$\{x^{(n)},y^{(n)}\}_{n=1}^N$ self-supervised:标签来自于数据本身（例如word2vec,BERT）|一部分有标注数据，一部分无标注数据，利用在有标注数据上训练的模型预测无标注数据，对于置信度较高的样本作为对应的标签重新训练模型| 训练集$\{x^{(n)}\}_{n=1}^N$ GAN|交互轨迹$\tau$和累计奖励$G_{\tau}$|
|优化目标|$y=f(x)$ 或 $p(y\|x)$ | |$p(x)$或带隐变量$z$的$p(x\|z)$|期望回报$E_{\tau}[G_{\tau}]$|
|学习准则|期望风险最小化；最大似然估计||最大似然估计；最小重构错误|策略评估，策略改进|

**最大似然估计：** 利用已知的样本$x$，找出最优可能生成该样本的参数$\theta$。[参考链接](https://zhuanlan.zhihu.com/p/55791843)

**期望风险最小化：** 机器学习算法的目标就是降低期望泛化误差（这个数据量被成为风险），选择期望风险最小的模型。[参考链接](https://www.cnblogs.com/ying-chease/p/10593123.html)

## 监督学习中模型的分类
Components in Supervised Training: Model, Loss Function, Objective, Optimization。

**判别式模型：**
- 直接学习条件概率分布$P(Y|X)$或决策函数$Y=f(X)$的形式的模型称为判别模型。
- 判别模型有感知机，K近邻，决策树，线性回归，支持向量机。
- 判别模型往往学习的准确率比较高，可以简化问题。

**生成式模型：**
- 首先学习联合概率分布$P(X,Y)$，从而求得条件概率分布$P(Y|X)$的模型。
- 生成模型有朴素贝叶斯，隐马尔可夫模型。
- 生成式模型可以还原出联合概率分布，学习收敛速度更快，当样本容量增加是，学习的模型可以更快收敛于真实模型；当隐变量存在时，仍可以用生成式模型学习，此时判别模型不能用。

**线性模型：**
- 决策边界为超平面或直线的模型称为线性模型。
- 线性模型有感知机，线性回归，逻辑回归，线性支持向量机。
- 非线性模型有k近邻，决策树，非线性支持向量机。

## 评估方法
- 留出法（hold-out）：直接将数据集划分成两个互斥的集合，其中一个集合作为训练集，另一个作为测试集。划分需要尽可能保持数据分布的一致性。
- 交叉验证法：先将数据集划分为k个大小相似的互斥子集，每个子集尽可能保持数据分布的一致性，每次用一个子集作为训练集，余下的子集作为测试集。从而可以进行k次训练和测试，最终返回的是这个测试结果的均值。
- 留一法：就是使得k等于数据集中数据的个数，每次只使用一个作为测试集，剩下的全部作为训练集，这种方法得到的结果与训练整个测试集的期望最为接近，但是成本过于庞大。
## 性能度量
### 回归问题
- 均方误差（Mean Square Error, MSE）:$MSE = \frac{1}{m}\sum_{i=1}^m(y_i-f(x_i))^2$ 
    - 均方误差指的就是模型预测值$f(X)$与真实样本$y$之间距离的平方的平均值。
    - MSE曲线的特点是光滑连续，可导，便于使用梯度下降算法，在最优点附近，梯度较小，有利于模型收敛。
    - 受离群点的影响较大。
- 平均绝对误差（Mean Absolute Error, MAE）:
    - 平均绝对误差制度就是预测值$f(x)$与$y$之间距离的平均值。
    - 连续但在$y-f(x)=0$处不可导。MAE大部分情况下梯度都是相等的，但是这意味着对于小的损失值，其梯度也是大的，这不利于函数的收敛和模型的学习。
    - 对离群点不那么敏感

>**在实际中，应该选择MSE还是MAE：**
从计算机求解梯度的复杂度来说，MSE 要优于 MAE，而且梯度也是动态变化的，能较快准确达到收敛。但是从离群点角度来看，如果离群点是实际数据或重要数据，而且是应该被检测到的异常值，那么我们应该使用MSE。另一方面，离群点仅仅代表数据损坏或者错误采样，无须给予过多关注，那么我们应该选择MAE作为损失。
### 分类问题
<h4>混淆矩阵:<h4>
<table border="1" width="500px" cellspacing="10">
<tr>
    <th colspan="2" rowspan="2" align="center"></th>
    <td colspan="2" align="center">预测结果</td>
</tr>
<tr>
    <td align="center">P</td>
    <td align="center">N</td>
</tr>
<tr>
    <td rowspan="2" align="center">真实情况</td>
    <td align="center">P</td>
    <td align="center">TP</td>
    <td align="center">FN</td>
</tr>
<tr>
    <td align="center">N</td>
    <td align="center">FP</td>
    <td align="center">TN</td>
</tr>
</table>

- 查准率/准确率：$P(precision)=\frac{TP}{TP+FP}$。预测是正例中预测正确的比例。
- 查全率/召回率：$R(recall)=\frac{TP}{TP+FN}$。实际是正例，预测对的比例。
#### F1度量：
F1度量是综合考虑查全率和查准率的性能度量，调和平均算法更重视较小的值。
$$
\frac{1}{F1}=\frac{1}{2}(\frac{1}{P}+\frac{1}{R})\\
F1 = \frac{2PR}{P+R}\\
若对查准率/查全率有不同偏好：\\
\frac{1}{F_{\beta}}=\frac{1}{1+\beta^2}(\frac{1}{P}+\frac{\beta^2}{R})\\
F_{\beta} = \frac{(1+\beta^2)}{\beta^2P+R}\\
\beta>1时对查全率有更大影响；\beta<1是查准率有更大影响
$$
## 过拟合和正则化
**过拟合**：过拟合指学习时选择的模型所包含的参数过多，以至出现出现这一模型**对已知数据预测得很好，但对未知数据预测得很差**的现象。

**正则化：** 引入了归纳偏好，即人为的“喜好”
### L0正则化
L0是指向量中非0的元素的个数。如果用L0来规则化一个参数矩阵W的话，就是希望W的大部分元素都是0。换句话说，让参数W是稀疏的。L0正则化的最优化问题是一个NP hard问题，L1正则化是L0正则化的最优凸近似。
### L1正则化
带L1正则化的回归也叫做Lasso回归。表现形式：
$$
λ \sum_{j=1}^n||\theta_j||
$$
代表向量中各个元素绝对值之和，λ为正则化系数。
L1正则化为什么可以防止过拟合？
> L1正则化之所以可以防止过拟合，是因为L1范数就是各个参数的绝对值相加得到的，**参数值大小和模型复杂度是成正比的**。因此如果拟合出一个复杂的模型（即出现了过拟合），其L1范数就大，这样L1正则化惩罚就高，整体损失函数就没有收敛，所以最终不会选择这些过拟合的参数。同时，L1正则化会使得参数稀疏，一部分参数的系数会变为0。
### L2正则化
带L2正则化的线性回归也叫做岭回归，Ridge回归，也叫做“权值衰减weight decay”，表现形式为：
$$
λ\sum_{j=1}^n\theta_j^2
$$
代表参数向量中各元素平方之和。L2正则化为什么可以防止过拟合？
> L2正则化会使得参数接近于0。越小的参数说明模型越简单，越简单的模型越不容易产生过拟合现象。\
同样的，**如果拟合出一个复杂的模型（即出现了过拟合），其L2范数就大，这样L2正则化惩罚就高**，整体损失函数就没有收敛，所以最终不会选择这些过拟合的参数。
### Dropout层
Dropout层在神经网络**训练时随机地让部分隐层神经元失效**，不进行权重参数和偏置进行更新，**降低了神经元之间的依赖性**，有效防止了模型过拟合。
## 偏差和方差
偏差（bias），方差（variance）。
在机器学习中，用训练数据集取训练一个模型，通常的做法是定义一个误差函数，通过将这个误差的最小化的过程来提高模型的性能。然而学习一个模型的目的是未来解决训练数据集这个领域中一般化的问题，单纯地将模型训练集最小化，并不能保证在解决一般化的问题时模型仍然是最优，甚至不能保证模型是可用的。这个训练数据集的损失与一般化的数据集的损失之间的差异就叫做**泛化误差**。

**泛化误差可以理解为偏差，方差与噪声之和。**

**偏差**度量了学习算法的期望预测与真实结果的偏离程度，即刻画了算法本身的拟合能力。

**方差**度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响。

**偏差度量的是单个模型的学习能力，而方差度量的是同一个模型在不同数据集上的稳定性。**

## 优化方法
### 优化在深度学习中的挑战
**局部最小点** 深度学习模型的⽬标函数可能有若⼲局部最优值。当⼀个优化问题的数值解在局部最优解附近时，由于
⽬标函数有关解的梯度接近或变成零，最终迭代求得的数值解可能只令⽬标函数局部最⼩化⽽⾮全局最
⼩化。\
**鞍点:**  梯度接近或变成零可能是由于当前解在局部最优解附近造成的。事实上，另⼀种可能性是当前解在鞍点（saddle point）附近。

**黑塞矩阵（Hessian Matrix）:** 黑塞矩阵是一个关于多变量函数的二阶偏导数构成的方阵。它包含了关于函数局部曲率和交叉导数的信息。黑塞矩阵可以用来判断一个点是否是局部最小值、局部最大值或鞍点。

**关于鞍点和黑塞矩阵之间的关系：**
在一个多变量函数的鞍点处，梯度（一阶导数）为零，黑塞矩阵可以用于进一步判断鞍点的性质。具体来说，如果在鞍点处黑塞矩阵的特征值中既有正值又有负值，那么这个鞍点是一个非退化鞍点，表示函数在该点的某个方向上曲率为正，而在另一个方向上曲率为负。这种情况下，函数在鞍点处既不是局部最小值也不是局部最大值。

### 牛顿法
$$
x_{k+1} = x_k - \frac{f'(x_k)}{f''(x_k)}
$$
### 梯度下降法
**批量梯度下降法（Batch Gradient Descent, BGD）:**
所有样本都参与更新。
- 优点：易于得到全局最优解，只要较少的迭代次数。
- 缺点：样本数目较大时的训练时间较长且收敛缓慢。

**随机梯度下降法(Stochastic Gradient Descent, SGD):**
每次从所有样本中随机抽取单个样本求解梯度。
- 优点：训练速度快，迭代计算量少。
- 缺点：准确度下降，难以获得群居最优解，总体迭代次数较多。

**小批量随机梯度下降法（Mini-Batch SGD）:**
是一种折中，每次随机从所有样本中抽取$k$个进行迭代求解梯度，每一次迭代的样本都是基于随机的方式进行抽取，因此样本会有重复。
- 优点：训练快，可以避免收敛到局部最优解。
- 缺点：准确度有一定程度上的下降。

批量大小越大，下降效果越明显，并且下降曲线越平滑，适量的批脸大小会导致更快的收敛。

### **动量法：**
相对于动量法（指数加权移动平均），小批量随机梯度下降法的缺点：
- 震荡和稳定性问题：SGD在更新参数时，根据小批量数据的梯度来进行迭代，这导师参数更新存在较大的不稳定性，可能导致模型参数在训练过程中产生震荡。动量法通过动量项来减轻这种震荡，但是SGD本身可能更容易收到数据噪声的影响，因此在某些情况下，动量法可能无法完全解决这个问题。
- 学习率选择：SGD通常需要仔细调整学习率，过小的学习率会导致收敛速度慢，而过大的学习率可能导致参数在优化过程中不稳定。动量法通过维护一个动量项，可以减轻学习率选择的问题。
- 局部极小值：SGD容易陷入局部极限值的问题，虽然动量法可以加速收敛，但不能总能客服局部极小值的问题。

时间步$t$时自变量为$\bm{x_t}$,学习率为$\eta_t$，梯度为$\bm{g_t}$。在实践部0，动量法创建速度变量$\bm{v_0}$，并将其元素初始化为0.动量法对每次迭代的步骤做如下修改：
$$
\bm{v_t}\leftarrow\gamma\bm{v_{t-1}}+\eta_t\bm{g_t},\\
\bm{x_t}\leftarrow\bm{x_{t-1}}-\bm{v_t}
$$
其中动量超参数$\gamma满足0\leq\gamma<1$。当$\gamma=0$时，动量法等价于下批量随机梯度下降法。

###  AdaGrad算法
之前的算法中，目标函数自变量的每一个元素在相同时间步都使用同一个学习率来自我迭代。AdaGrad算法根据自变量在每个维度的梯度值的大小来调整各个维度上的学习率，从而避免统一的学习率难以适应所有的维度问题。\
在时间步0，AdaGrad将$\bm{s_0}$中每个元素初始化为。在时间步$t$：
$$
\bm{s_t}\leftarrow\bm{s_{t-1}}+\bm{g_t}\odot\bm{g_t},\\
\bm{x_t}\leftarrow\bm{x_{t-1}}-\frac{\eta}{\sqrt{\bm{s_t}+\epsilon}}\odot\bm{g_t}
$$
其中$\eta$是学习率，$\epsilon$是未来维持数值稳定性而添加的很小的常数。小批量随机梯度按元素平方的累加变量$\bm{s_t}$出现在学习率的分母想中。因此，如果目标函数有关自变量中某个元素的偏导数一致较大，那么该元素的学习率将下降较快；反之，如果目标函数有关自变量中某个元素的偏导数一直较小，那么该元素的学习率将下降较慢。然而，由于$\bm{s_t}$一直在累加按元素平方的梯度，自变量中每个元素的学习率在迭代过程中一直在降低。所以，当学习率在迭代早起降得较快且当前解依然不佳是，AdaGrad算法在迭代后期由于学习率过小，可能难以找到一个有用的解。
### RMSPropo
不同于AdaGrad算法里状态变量$\bm{s_t}$是截至实践部$t$所有小批量随机梯度$g_t$按元素平方和，RMSProp算法将这些梯度按元素平方做指数加权移动平均。具体来说，在给定超参数$0\leq\gamma<1$，RMSProp在时间步$t>0$计算：
$$
\bm{s_t}\leftarrow\gamma\bm{s_{t-1}}+(1-\gamma)\bm{g_t}\odot\bm{g_t},
$$
和AdaGrad算法一样，RMSProp算法将目标函数自变量中每个元素的学习率通过按元素运算重新调整，然后更新自变量：
$$
\bm{x_t}\leftarrow\bm{x_{t-1}}-\frac{\eta}{\sqrt{\bm{s_t}+\epsilon}}\odot\bm{g_t}
$$
因为RMSProp算法对状态变量$\bm{s_t}$是对平方项$\bm{g_t}\odot\bm{g_t}$的指数加权移动平均，所以可以看作是最近$1/(1-\gamma)$个时间步的小批量随机梯度平方项的加权平均。如此，自变量每个元素的学习率在迭代过程中就不再一直降低。
### AdaDelta
AdaDelta没有学习率这一超参数。给定超参数$0\leq\gamma<1$，在时间步$t>0$：
$$
\bm{s_t}\leftarrow\gamma\bm{s_{t-1}}+(1-\gamma)\bm{g_t}\odot\bm{g_t},
$$
AdaDelta算法还维护一个额外的状态变量$Δ\bm{x_t}$，其元素同样在时间步0时被初始化为0.使用$Δ\bm{x_{t-1}}$来计算自变量的变化量：
$$
\bm{g'_t} \leftarrow \sqrt{\frac{Δ\bm{x_{t-1}+\epsilon}}{\bm{s_t}+\epsilon}}\odot\bm{g_t}\\
\bm{x_t}\leftarrow\bm{x_{t-1}}-\bm{g'_t}\\
Δ\bm{x_t}\leftarrow\gammaΔ\bm{x_{t-1}}+(1-\gamma)\bm{g'_t}\odot\bm{g'_t}
$$
与RMSProp不同的是AdaDelta使用$\sqrt{Δ\bm{x_{t-1}}}$代替学习率$\eta$
### Adam
Adam算法在RMSProp算法基础上对小批量随机梯度做了指数加权移动平均。所以Adam算法可以看作是RMSProp算法与动量法的结合。\
Adam算法使用了动量变量$\bm{v_t}$和RMSProp算法中小批量随机梯度按元素平方的指数加权移动平均变量$\bm{s_t}$，并在时间步0将它们初始化为0。给定超参数$0\leq\beta_1<(算法作者建议设置为0.9)$，时间步$t$的动量变量$\bm{v_t}$即小批量随机梯度$\bm{g_t}$的指数加权移动平均：
$$
\bm{v_t}\leftarrow\beta_1\bm{v_{t-1}}+(1-\beta_1)\bm{g_t}
$$
和RMSProp算法中一样，给定超参数$0\leq\beta_2<(算法作者建议设置为0.999)$，将小批量随机梯度按元素平方后的项$\bm{g_t}\odot\bm{g_t}$做指数加权移动平均得到$\bm{s_t}$:
$$
\bm{s_t}\leftarrow\beta_2\bm{s_{t-1}}+(1-\beta_2)\bm{g_t}\odot\bm{g_t}
$$
做偏差修正：
$$
\hat{\bm{v}}_t\leftarrow\frac{\bm{v_t}}{1-\beta_1^t},\\
\hat{\bm{s}}_t\leftarrow\frac{\bm{s_t}}{1-\beta_2^t},
$$
将模型参数中每个元素的学习率通过按元素运算重新调整，迭代自变量：
$$
\bm{g'_t}\leftarrow\frac{\eta\hat{\bm{v}}_t}{\sqrt{\hat{\bm{s}}_t}+\epsilon}\\
\bm{x_t}\leftarrow\bm{x_{t-1}}-\bm{g'_t}
$$
## 机器学习著名理论
### PAC（Probably Approximately）学习理论
PAC学习理论即可能近似正确学习理论，PAC学习理论认为从有限的训练样本上学习到期望错误为0的模型是不切实际的，应该只要求学习算法可以以一定的概率学习到一个近似正确的假设。PAC学习理论可以帮助分析一个机器学习方法在什么条件下可以学习到一个近似正确的分类器。如果希望模型的假设空间越大（复杂度越大），泛化错误越小，其需要的样本数量越多。
### 没有免费午餐定理
如果一个算法对某些问题有效，那么它一定在另外一些问题上比纯随机搜索算法更差。即不存在一种机器学习算法使用阈任何领域或任务。\
即一个算法A在一个问题Q1上表现比B差，则一定存在一个问题Q2，在问题Q2上算法A比B表现更好。
### 奥卡姆剃刀原理
在所有可能选择的模型中，能够很好地解释已知数据并且十分简单才是最好的模型。
### 丑小鸭定理
丑小鸭与白天鹅之间的区别和两只白天鹅之间的区别一样大。因为世界上不存在相似性的客观标准，一切相似性的标准都是主观的。
### 归纳偏置
在机器学习中，很多学习算法经常会对学习的问题做一些关于目标函数的必要假设，成为归纳偏置（Inductive Bias）。
 **归纳 (Induction)** 是自然科学中常用的两大方法之一 (归纳与演绎，Induction & Deduction)，指从一些例子中寻找共性、泛化，形成一个较通用的规则的过程。**偏置 (Bias)** 则是指对模型的偏好，以下展示了 **4 种解释**：
- **通俗理解：** 归纳偏置可以理解为，从现实生活中观察到的现象中归纳出一定的规则 (heuristics)，然后对模做一定的约束，从而可以起到 “模型选择” 的作用，类似贝叶斯学习中的 “先验”。
- **西瓜书解释：** 机器学习算法在学习过程中对某种类型假设的偏好，称为 归纳偏好。归纳偏好可以看作学习算法自身在一个庞大的假设空间中对假设进行选择的启发式或 “价值观”。
- **维基百科解释：** 如果学习器需要去预测 “其未遇到过的输入” 的结果时，则需要一些 假设 来 帮助它做出选择。
- **广义解释：** 归纳偏置会促使学习算法优先考虑具有某些属性的解。\
例如，**深度神经网络** 偏好性地认为，层次化处理信息有更好效果；**卷积神经网络** 认为信息具有空间局部性，可用滑动卷积共享权重的方式降低参数空间；**循环神经网络** 则将时序信息纳入考虑，强调顺序重要性；**图网络** 则认为中心节点与邻居节点的相似性会更好地引导信息流动。
## 特征工程
特征工程是指用一系列工程化的方式从原始数据中筛选出更好的数据特征，以提升模型的训练效果。
如何让机器自动地学习到有效的特征也称为特征学习，也叫表示学习。特征学习在一定程度上可以减少模型的复杂性，缩短训练时间，提高模型泛化能力，避免过拟合。
### 数据清洗
- 忽略元组
- 人工填写空缺值
- 用一个全局变量填充空缺值：比如使用 unknown 或∞
- 使用属性的平均值填充空缺值
- 使用与给定元组属同一类的所有样本的平均值
- 使用最可能的值填充空缺值：使用像 Bayesian 公式，knn 或判定树这样的基于推断的方法。
### 数据预处理 Preprocessing
**数据无量纲化：** 将不同规格的数据转换到统一规格，或不同分不的数据转换到某一特定分布的需求，这种需求统称为数据“无量纲化”。\
**目的：**

- 加快求解速度
- 提升模型精度
- 避免某一个取值范围特别大的特征对距离计算造成影响

方法：
- 中心化：让所有数据减去一个固定值，即让所有数据样本平移到某个位置
- 缩放：通过除以某个固定值，即将数据固定在某个范围内，取对数也是一种缩放处理。
#### 数据归一化（Normalization/Min-Max Scaling）
$$
x^* = \frac{x-min(x)}{max(x)-min(x)}
$$
#### 数据标准化（Standardization/Z-score normalization）
$$
x^* = \frac{x-μ}{\sigma}\\
均值-μ\ \ \ \ \ \ 标准差-\sigma
$$
### 处理非数值型数据
对于离散的属性，变为数值时要考虑“序”。例如身高中“高，中，低”有“序”的关系，可以直接变为数值“1.0,0.5,0.0”；对于西瓜颜色，没有“序”，则转变为one-hot向量。

